{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = \"adult.csv\"\n",
        "\n",
        "# Caricamento del dataset e gestione dei valori mancanti\n",
        "try:\n",
        "    df = pd.read_csv(file_path, na_values='?')\n",
        "except FileNotFoundError:\n",
        "    print(f\"Errore: File '{file_path}' non trovato. Assicurati che il file sia presente.\")\n",
        "    exit()\n",
        "\n",
        "# Eliminazione delle righe con valori mancanti\n",
        "df = df.dropna()\n",
        "\n",
        "# Preprocessing iniziale delle feature\n",
        "# Mappatura delle colonne 'gender' e 'income' a valori numerici\n",
        "df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
        "df['high_income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
        "df.drop('income', axis=1, inplace=True)\n",
        "\n",
        "# Raggruppamento della colonna 'native-country'\n",
        "df['native-country'] = df['native-country'].apply(lambda x: 'Other' if x != 'United-States' else x)\n",
        "\n",
        "# Eliminazione di colonne non necessarie o ridondanti\n",
        "df.drop('education', axis=1, inplace=True)\n",
        "df.drop('fnlwgt', axis=1, inplace=True)\n",
        "\n",
        "# Separazione delle feature (X) e del target (y)\n",
        "X = df.drop('high_income', axis=1)\n",
        "y = df['high_income']\n",
        "\n",
        "# Divisione del dataset in training set e test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Identificazione delle feature categoriche e numeriche\n",
        "categorical_features_to_encode = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
        "numerical_features = ['age', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'gender']\n",
        "\n",
        "# Creazione di copie per l'encoding e la scalatura\n",
        "X_train_processed = X_train.copy()\n",
        "X_test_processed = X_test.copy()\n",
        "\n",
        "# Applicazione dell'Ordinal Encoding alle feature categoriche\n",
        "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X_train_processed[categorical_features_to_encode] = ordinal_encoder.fit_transform(X_train[categorical_features_to_encode])\n",
        "X_test_processed[categorical_features_to_encode] = ordinal_encoder.transform(X_test[categorical_features_to_encode])\n",
        "\n",
        "# Scalatura delle feature numeriche usando StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_processed[numerical_features] = scaler.fit_transform(X_train_processed[numerical_features])\n",
        "X_test_processed[numerical_features] = scaler.transform(X_test_processed[numerical_features])\n",
        "\n",
        "# Inizializzazione e addestramento del modello LightGBM\n",
        "print(\"\\nInizio addestramento del modello LightGBM...\")\n",
        "lgbm_model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbose=-1)\n",
        "lgbm_model.fit(X_train_processed, y_train)\n",
        "print(\"Addestramento completato.\")\n",
        "\n",
        "# Effettuare predizioni sul test set\n",
        "print(\"\\nEffettuo predizioni sul test set...\")\n",
        "y_pred_lgbm = lgbm_model.predict(X_test_processed)\n",
        "y_pred_proba_lgbm = lgbm_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "# Valutazione del Modello\n",
        "print(\"\\n--- Valutazione del Modello LightGBM ---\")\n",
        "accuracy = accuracy_score(y_test, y_pred_lgbm)\n",
        "print(f\"Accuratezza: {accuracy:.4f}\")\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_lgbm)\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_lgbm, target_names=['<=50K', '>50K']))\n",
        "print(\"\\nMatrice di Confusione:\")\n",
        "cm = confusion_matrix(y_test, y_pred_lgbm)\n",
        "print(pd.DataFrame(cm, index=['Reale: <=50K', 'Reale: >50K'], columns=['Predetto: <=50K', 'Predetto: >50K']))\n",
        "\n",
        "# Spiegazione del Modello con SHAP\n",
        "print(\"\\n--- Spiegazione del Modello LightGBM con SHAP ---\")\n",
        "explainer = shap.TreeExplainer(lgbm_model)\n",
        "print(\"SHAP Explainer creato.\")\n",
        "print(\"Calcolo dei valori SHAP per il test set (basato su X_test_processed)...\")\n",
        "shap_values = explainer.shap_values(X_test_processed)\n",
        "print(\"Calcolo dei valori SHAP completato.\")\n",
        "\n",
        "# Determinazione di expected_value e shap_values per la classe positiva\n",
        "base_expected_value = explainer.expected_value\n",
        "shap_values_positive_class = shap_values\n",
        "\n",
        "if isinstance(shap_values, list) and len(shap_values) == 2:\n",
        "    shap_values_positive_class = shap_values[1]\n",
        "    if isinstance(base_expected_value, list) and len(base_expected_value) == 2:\n",
        "        expected_value_positive_class = base_expected_value[1]\n",
        "    else:\n",
        "        expected_value_positive_class = base_expected_value\n",
        "else:\n",
        "    expected_value_positive_class = base_expected_value\n",
        "\n",
        "# Visualizzazione dell'importanza globale delle feature (Bar Plot)\n",
        "print(\"\\nGenerazione del Summary Plot SHAP (bar)...\")\n",
        "plt.figure()\n",
        "shap.summary_plot(shap_values_positive_class, X_test_processed, plot_type=\"bar\", show=False)\n",
        "plt.title(\"Importanza Globale delle Feature (LightGBM - SHAP Summary Plot - Bar)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Summary Plot (bar) generato e mostrato.\")\n",
        "\n",
        "# Visualizzazione dell'importanza e dell'impatto delle feature (Dot Plot)\n",
        "print(\"\\nGenerazione del Summary Plot SHAP (dot)...\")\n",
        "plt.figure()\n",
        "shap.summary_plot(shap_values_positive_class, X_test, feature_names=X_test_processed.columns, show=False)\n",
        "plt.title(\"Importanza e Impatto delle Feature (LightGBM - SHAP Summary Plot - Dot)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Summary Plot (dot) generato e mostrato.\")\n",
        "\n",
        "# Visualizzazione dell'impatto di una singola feature (Dependence Plot)\n",
        "feature_to_plot = 'age'\n",
        "if feature_to_plot in X_test_processed.columns:\n",
        "    print(f\"\\nGenerazione del Dependence Plot SHAP per '{feature_to_plot}'...\")\n",
        "    plt.figure()\n",
        "    shap.dependence_plot(feature_to_plot, shap_values_positive_class, X_test, feature_names=X_test_processed.columns, interaction_index=\"auto\", show=False)\n",
        "    plt.title(f\"SHAP Dependence Plot per '{feature_to_plot}' (LightGBM - valori X originali/non scalati)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"Dependence Plot per '{feature_to_plot}' generato e mostrato.\")\n",
        "else:\n",
        "    print(f\"\\nLa feature '{feature_to_plot}' non è presente nelle colonne. Impossibile generare il dependence plot.\")\n",
        "\n",
        "# Spiegazione di predizioni individuali con Force Plot\n",
        "print(\"\\n--- Spiegazione di Predizioni Individuali con SHAP Force Plot (LightGBM) ---\")\n",
        "num_predictions_to_explain = 3\n",
        "print(f\"Generazione dei Force Plot SHAP per le prime {num_predictions_to_explain} istanze del test set...\")\n",
        "\n",
        "for i in range(min(num_predictions_to_explain, X_test_processed.shape[0])):\n",
        "    print(f\"\\nSpiegazione per l'istanza {i} del test set:\")\n",
        "    try:\n",
        "        instance_features_for_display = X_test.iloc[i].copy()\n",
        "        if 'gender' in instance_features_for_display.index:\n",
        "            instance_features_for_display['gender'] = 'Female' if instance_features_for_display['gender'] == 1 else 'Male'\n",
        "\n",
        "        current_shap_values_instance = shap_values_positive_class[i,:]\n",
        "\n",
        "        plt.figure(figsize=(30, 10))\n",
        "        shap.force_plot(expected_value_positive_class,\n",
        "                         current_shap_values_instance,\n",
        "                         instance_features_for_display,\n",
        "                         feature_names=X_test_processed.columns,\n",
        "                         matplotlib=True, show=False, text_rotation=10)\n",
        "        plt.title(f\"SHAP Force Plot per Istanza {i} (LightGBM - Valori Feature Originali/Mappati)\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(f\"Force Plot (Matplotlib) per l'istanza {i} generato e mostrato.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante la generazione del force plot Matplotlib per l'istanza {i}: {e}\")\n",
        "\n",
        "if X_test_processed.shape[0] < num_predictions_to_explain:\n",
        "    print(f\"\\nAttenzione: richieste {num_predictions_to_explain} spiegazioni (force plot), ma il test set ha solo {X_test_processed.shape[0]} istanze.\")\n",
        "\n",
        "# Spiegazione di più predizioni con Decision Plot\n",
        "print(\"\\n--- Spiegazione di Predizioni Multiple con SHAP Decision Plot (LightGBM) ---\")\n",
        "num_decision_plots = 5\n",
        "if X_test_processed.shape[0] >= num_decision_plots:\n",
        "    shap_values_subset_for_decision = shap_values_positive_class[:num_decision_plots, :]\n",
        "    features_subset_for_decision = X_test.iloc[:num_decision_plots]\n",
        "\n",
        "    print(f\"\\nGenerazione del Decision Plot SHAP per le prime {num_decision_plots} istanze...\")\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.decision_plot(expected_value_positive_class,\n",
        "                           shap_values_subset_for_decision,\n",
        "                           features_subset_for_decision,\n",
        "                           feature_names=X_test_processed.columns.tolist(),\n",
        "                           show=False,\n",
        "                          )\n",
        "        plt.title(f\"SHAP Decision Plot per le prime {num_decision_plots} istanze (LightGBM)\")\n",
        "        plt.show()\n",
        "        print(f\"Decision Plot per le prime {num_decision_plots} istanze generato e mostrato.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante la generazione del decision plot: {e}\")\n",
        "else:\n",
        "    print(f\"\\nNon ci sono abbastanza istanze nel test set ({X_test_processed.shape[0]}) per generare il decision plot per {num_decision_plots} istanze.\")\n",
        "\n",
        "print(\"\\n--- Analisi SHAP completata ---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "LCeibspjaX3R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKdyLqj9aZnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cS-_rrMkaZ2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
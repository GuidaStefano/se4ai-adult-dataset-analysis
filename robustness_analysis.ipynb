{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from art.estimators.classification import SklearnClassifier, BlackBoxClassifier\n",
        "from art.attacks.evasion import HopSkipJump\n",
        "from art.utils import to_categorical\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Caricamento e Preprocessing dei Dati\n",
        "file_path = \"adult.csv\"\n",
        "try:\n",
        "    df = pd.read_csv(file_path, na_values='?')\n",
        "except FileNotFoundError:\n",
        "    print(f\"Errore: File '{file_path}' non trovato. Assicurati che il file sia presente.\")\n",
        "    exit()\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df['gender'] = df['gender'].map({'Male': 0, 'Female': 1}).astype(int)\n",
        "df['high_income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
        "df.drop('income', axis=1, inplace=True)\n",
        "\n",
        "df['native-country'] = df['native-country'].apply(lambda x: 'Other' if x != 'United-States' else x)\n",
        "\n",
        "df.drop('education', axis=1, inplace=True)\n",
        "df.drop('fnlwgt', axis=1, inplace=True)\n",
        "\n",
        "X = df.drop('high_income', axis=1)\n",
        "y = df['high_income']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "categorical_features_to_encode = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
        "numerical_features = ['age', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'gender']\n",
        "\n",
        "X_train_processed = X_train.copy()\n",
        "X_test_processed = X_test.copy()\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X_train_processed[categorical_features_to_encode] = ordinal_encoder.fit_transform(X_train[categorical_features_to_encode])\n",
        "X_test_processed[categorical_features_to_encode] = ordinal_encoder.transform(X_test[categorical_features_to_encode])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_processed[numerical_features] = scaler.fit_transform(X_train_processed[numerical_features])\n",
        "X_test_processed[numerical_features] = scaler.transform(X_test_processed[numerical_features])\n",
        "\n",
        "X_train_processed = X_train_processed.astype(np.float32)\n",
        "X_test_processed = X_test_processed.astype(np.float32)\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "# Addestramento del Modello LightGBM Originale\n",
        "print(\"\\n--- Addestramento del Modello LightGBM Originale ---\")\n",
        "lgbm_model_orig = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbosity=-1)\n",
        "lgbm_model_orig.fit(X_train_processed, y_train)\n",
        "print(\"Addestramento modello originale completato.\")\n",
        "\n",
        "# Valutazione del Modello Originale\n",
        "print(\"\\n--- Valutazione del Modello LightGBM Originale (su dati puliti) ---\")\n",
        "y_pred_orig = lgbm_model_orig.predict(X_test_processed)\n",
        "y_pred_proba_orig = lgbm_model_orig.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_orig = accuracy_score(y_test, y_pred_orig)\n",
        "roc_auc_orig = roc_auc_score(y_test, y_pred_proba_orig)\n",
        "print(f\"Accuratezza Originale: {accuracy_orig:.4f}\")\n",
        "print(f\"ROC AUC Score Originale: {roc_auc_orig:.4f}\")\n",
        "\n",
        "# Preparazione del Classificatore per ART\n",
        "min_val = np.min(X_train_processed.values)\n",
        "max_val = np.max(X_train_processed.values)\n",
        "clip_values = (min_val, max_val)\n",
        "\n",
        "art_classifier_orig = BlackBoxClassifier(\n",
        "    predict_fn=lgbm_model_orig.predict_proba,\n",
        "    input_shape=X_train_processed.shape[1:],\n",
        "    nb_classes=2,\n",
        "    clip_values=clip_values,\n",
        ")\n",
        "print(\"\\nModello originale wrappato per ART con BlackBoxClassifier (usando predict_proba).\")\n",
        "\n",
        "# Simulazione di Attacco di Evasione (HopSkipJump)\n",
        "print(\"\\n--- Simulazione Attacco di Evasione (HopSkipJump) ---\")\n",
        "n_evasion_samples = 50\n",
        "if len(X_test_processed) > n_evasion_samples:\n",
        "    X_test_subset_evasion = X_test_processed.iloc[:n_evasion_samples].values\n",
        "    y_test_subset_evasion = y_test.iloc[:n_evasion_samples].values\n",
        "else:\n",
        "    X_test_subset_evasion = X_test_processed.values\n",
        "    y_test_subset_evasion = y_test.values\n",
        "    n_evasion_samples = len(X_test_processed)\n",
        "\n",
        "attack_evasion = HopSkipJump(classifier=art_classifier_orig,\n",
        "                             targeted=False,\n",
        "                             max_iter=10,\n",
        "                             max_eval=100,\n",
        "                             init_eval=10,\n",
        "                             verbose=False)\n",
        "\n",
        "print(f\"Generazione di {n_evasion_samples} campioni avversari di evasione (può richiedere tempo)...\")\n",
        "X_test_adversarial_evasion = attack_evasion.generate(x=X_test_subset_evasion)\n",
        "print(\"Generazione campioni avversari di evasione completata.\")\n",
        "\n",
        "y_pred_evasion_attack_proba = art_classifier_orig.predict(X_test_adversarial_evasion)\n",
        "y_pred_evasion_attack_labels = np.argmax(y_pred_evasion_attack_proba, axis=1)\n",
        "\n",
        "accuracy_evasion_attack = accuracy_score(y_test_subset_evasion, y_pred_evasion_attack_labels)\n",
        "roc_auc_evasion_attack = roc_auc_score(y_test_subset_evasion, y_pred_evasion_attack_proba[:, 1])\n",
        "\n",
        "print(f\"Accuratezza del modello originale su {n_evasion_samples} campioni avversari di evasione: {accuracy_evasion_attack:.4f}\")\n",
        "print(f\"ROC AUC del modello originale su {n_evasion_samples} campioni avversari di evasione: {roc_auc_evasion_attack:.4f}\")\n",
        "\n",
        "\n",
        "# Simulazione Attacco di Poisoning (Label Flipping)\n",
        "print(\"\\n--- Simulazione Attacco di Poisoning (Label Flipping) ---\")\n",
        "\n",
        "poison_percentage = 0.40\n",
        "n_poison = int(poison_percentage * len(X_train_processed))\n",
        "\n",
        "X_train_poisoned = X_train_processed.copy()\n",
        "y_train_poisoned = y_train.copy()\n",
        "\n",
        "lgbm_temp = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbose=-1)\n",
        "lgbm_temp.fit(X_train_processed, y_train)\n",
        "y_pred_proba_temp = lgbm_temp.predict_proba(X_train_processed)[:, 1]\n",
        "\n",
        "uncertainty = np.abs(y_pred_proba_temp - 0.5)\n",
        "\n",
        "poison_indices_sorted = np.argsort(uncertainty)\n",
        "poison_indices = X_train_processed.index[poison_indices_sorted[:n_poison]]\n",
        "\n",
        "y_train_poisoned.loc[poison_indices] = 1 - y_train_poisoned.loc[poison_indices]\n",
        "print(f\"{n_poison} etichette flippate strategicamente nel training set per l'attacco di poisoning.\")\n",
        "\n",
        "lgbm_model_poisoned = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbosity=-1)\n",
        "lgbm_model_poisoned.fit(X_train_poisoned, y_train_poisoned)\n",
        "print(\"Addestramento modello su dati avvelenati strategicamente completato.\")\n",
        "\n",
        "y_pred_poisoned_model = lgbm_model_poisoned.predict(X_test_processed)\n",
        "y_pred_proba_poisoned_model = lgbm_model_poisoned.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_poisoned_model = accuracy_score(y_test, y_pred_poisoned_model)\n",
        "roc_auc_poisoned_model = roc_auc_score(y_test, y_pred_proba_poisoned_model)\n",
        "print(f\"Accuratezza del modello avvelenato (su dati di test puliti): {accuracy_poisoned_model:.4f}\")\n",
        "print(f\"ROC AUC Score del modello avvelenato (su dati di test puliti): {roc_auc_poisoned_model:.4f}\")\n",
        "\n",
        "# Difesa: Addestramento Avversario\n",
        "print(\"\\n--- Difesa: Addestramento Avversario ---\")\n",
        "n_adv_train_samples = 200\n",
        "if len(X_train_processed) > n_adv_train_samples:\n",
        "    X_train_subset_for_adv_df_indexed = X_train_processed.sample(n=n_adv_train_samples, random_state=42)\n",
        "    X_train_subset_for_adv = X_train_subset_for_adv_df_indexed.values\n",
        "else:\n",
        "    X_train_subset_for_adv_df_indexed = X_train_processed.copy()\n",
        "    X_train_subset_for_adv = X_train_subset_for_adv_df_indexed.values\n",
        "    n_adv_train_samples = len(X_train_processed)\n",
        "\n",
        "print(f\"Generazione di {n_adv_train_samples} campioni avversari dal training set per l'addestramento (può richiedere tempo)...\")\n",
        "attack_adv_training = HopSkipJump(classifier=art_classifier_orig,\n",
        "                                  targeted=False,\n",
        "                                  max_iter=10,\n",
        "                                  max_eval=100,\n",
        "                                  init_eval=10,\n",
        "                                  verbose=False)\n",
        "X_train_adversarial_generated = attack_adv_training.generate(x=X_train_subset_for_adv)\n",
        "print(\"Generazione campioni avversari per l'addestramento completata.\")\n",
        "\n",
        "X_train_adversarial_generated_df = pd.DataFrame(X_train_adversarial_generated, columns=X_train_processed.columns)\n",
        "y_train_subset_for_adv_labels = y_train.loc[X_train_subset_for_adv_df_indexed.index]\n",
        "\n",
        "X_train_augmented = pd.concat([X_train_processed, X_train_adversarial_generated_df], ignore_index=True)\n",
        "y_train_augmented = pd.concat([y_train, y_train_subset_for_adv_labels], ignore_index=True)\n",
        "\n",
        "print(f\"Dimensione training set originale: {X_train_processed.shape}, Aumentato a: {X_train_augmented.shape}\")\n",
        "\n",
        "lgbm_model_adv_trained = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbosity=-1)\n",
        "lgbm_model_adv_trained.fit(X_train_augmented, y_train_augmented)\n",
        "print(\"Addestramento modello avversario completato.\")\n",
        "\n",
        "# Valutazione del Modello Addestrato Avversariamente\n",
        "print(\"\\n--- Valutazione Modello Addestrato Avversariamente ---\")\n",
        "y_pred_adv_trained_clean = lgbm_model_adv_trained.predict(X_test_processed)\n",
        "y_pred_proba_adv_trained_clean = lgbm_model_adv_trained.predict_proba(X_test_processed)[:, 1]\n",
        "accuracy_adv_trained_clean = accuracy_score(y_test, y_pred_adv_trained_clean)\n",
        "roc_auc_adv_trained_clean = roc_auc_score(y_test, y_pred_proba_adv_trained_clean)\n",
        "print(f\"Accuratezza modello add. avversariamente (su dati test puliti): {accuracy_adv_trained_clean:.4f}\")\n",
        "print(f\"ROC AUC modello add. avversariamente (su dati test puliti): {roc_auc_adv_trained_clean:.4f}\")\n",
        "\n",
        "art_classifier_adv_trained = BlackBoxClassifier(\n",
        "    predict_fn=lgbm_model_adv_trained.predict_proba,\n",
        "    input_shape=X_test_processed.shape[1:],\n",
        "    nb_classes=2,\n",
        "    clip_values=clip_values,\n",
        ")\n",
        "\n",
        "y_pred_adv_trained_adv_test_proba = art_classifier_adv_trained.predict(X_test_adversarial_evasion)\n",
        "y_pred_adv_trained_adv_test_labels = np.argmax(y_pred_adv_trained_adv_test_proba, axis=1)\n",
        "\n",
        "accuracy_adv_trained_adv_test = accuracy_score(y_test_subset_evasion, y_pred_adv_trained_adv_test_labels)\n",
        "roc_auc_adv_trained_adv_test = roc_auc_score(y_test_subset_evasion, y_pred_adv_trained_adv_test_proba[:, 1])\n",
        "\n",
        "print(f\"Accuratezza modello add. avversariamente (su {n_evasion_samples} dati test avversari): {accuracy_adv_trained_adv_test:.4f}\")\n",
        "print(f\"ROC AUC modello add. avversariamente (su {n_evasion_samples} dati test avversari): {roc_auc_adv_trained_adv_test:.4f} (su {n_evasion_samples} campioni)\")\n",
        "\n",
        "# Riepilogo dei Risultati\n",
        "print(\"\\n--- Riepilogo Risultati ---\")\n",
        "print(f\"Modello Originale (su dati puliti):          Accuratezza={accuracy_orig:.4f}, ROC AUC={roc_auc_orig:.4f}\")\n",
        "print(f\"Modello Originale (sotto attacco evasione): Accuratezza={accuracy_evasion_attack:.4f}, ROC AUC={roc_auc_evasion_attack:.4f} (su {n_evasion_samples} campioni)\")\n",
        "print(f\"Modello Avvelenato (su dati puliti):         Accuratezza={accuracy_poisoned_model:.4f}, ROC AUC={roc_auc_poisoned_model:.4f}\")\n",
        "print(f\"Modello Add. Avversariamente (dati puliti): Accuratezza={accuracy_adv_trained_clean:.4f}, ROC AUC={roc_auc_adv_trained_clean:.4f}\")\n",
        "print(f\"Modello Add. Avversariamente (dati avv.):   Accuratezza={accuracy_adv_trained_adv_test:.4f}, ROC AUC={roc_auc_adv_trained_adv_test:.4f} (su {n_evasion_samples} campioni)\")\n",
        "\n",
        "print(\"\\nSimulazione completata.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ChVrY6wIdFEm"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

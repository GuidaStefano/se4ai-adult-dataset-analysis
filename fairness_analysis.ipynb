{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "from fairlearn.metrics import MetricFrame\n",
        "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio\n",
        "from fairlearn.metrics import equalized_odds_difference, equalized_odds_ratio\n",
        "from fairlearn.metrics import selection_rate, false_positive_rate, true_positive_rate, count\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "sns.set_style('whitegrid')\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Caricamento e Preprocessing dei Dati\n",
        "file_path = \"adult.csv\"\n",
        "try:\n",
        "    df_original = pd.read_csv(file_path, na_values='?')\n",
        "except FileNotFoundError:\n",
        "    print(f\"Errore: File '{file_path}' non trovato.\")\n",
        "    df_original = pd.DataFrame()\n",
        "\n",
        "df = df_original.copy()\n",
        "if not df.empty:\n",
        "    df = df.dropna()\n",
        "\n",
        "    df['high_income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
        "    df.drop('income', axis=1, inplace=True)\n",
        "\n",
        "    df['gender_original'] = df['gender']\n",
        "    df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "    df['race_original'] = df['race']\n",
        "    df['race_binary'] = df['race'].apply(lambda x: 'White' if x.strip() == 'White' else 'Non-White')\n",
        "    df['race'] = df['race_binary'].map({'Non-White': 0, 'White': 1})\n",
        "\n",
        "    df['native-country'] = df['native-country'].apply(lambda x: 'Other' if x.strip() != 'United-States' else 'United-States')\n",
        "    df.drop(['education', 'fnlwgt', 'race_binary'], axis=1, inplace=True)\n",
        "\n",
        "    X_raw = df.drop('high_income', axis=1)\n",
        "    y = df['high_income']\n",
        "\n",
        "    sensitive_features_gender_series = X_raw['gender']\n",
        "    sensitive_features_race_series = X_raw['race']\n",
        "\n",
        "    X_model_input = X_raw.drop(['gender_original', 'race_original'], axis=1)\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X_model_input, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    X_test_sensitive_gender = X_test_raw['gender']\n",
        "    X_test_sensitive_race = X_test_raw['race']\n",
        "    X_train_sensitive_gender_raw = X_train_raw['gender']\n",
        "    X_train_sensitive_race_raw = X_train_raw['race']\n",
        "\n",
        "    categorical_features_to_encode = ['workclass', 'marital-status', 'occupation', 'relationship', 'native-country']\n",
        "    numerical_features = ['age', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'gender', 'race']\n",
        "\n",
        "    def preprocess_data(X_train_df, X_test_df, cat_feats, num_feats):\n",
        "        X_train_p = X_train_df.copy()\n",
        "        X_test_p = X_test_df.copy()\n",
        "\n",
        "        ordinal_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "        X_train_p[cat_feats] = ordinal_enc.fit_transform(X_train_df[cat_feats])\n",
        "        X_test_p[cat_feats] = ordinal_enc.transform(X_test_df[cat_feats])\n",
        "\n",
        "        scaler_func = StandardScaler()\n",
        "        X_train_p[num_feats] = scaler_func.fit_transform(X_train_p[num_feats])\n",
        "        X_test_p[num_feats] = scaler_func.transform(X_test_p[num_feats])\n",
        "        return X_train_p, X_test_p, ordinal_enc, scaler_func\n",
        "\n",
        "    X_train_processed, X_test_processed, _, _ = preprocess_data(\n",
        "        X_train_raw, X_test_raw, categorical_features_to_encode, numerical_features\n",
        "    )\n",
        "\n",
        "    print(\"Dimensioni X_train_processed:\", X_train_processed.shape)\n",
        "    print(\"Dimensioni X_test_processed:\", X_test_processed.shape)\n",
        "else:\n",
        "    print(\"Dataset vuoto, saltare le celle successive.\")\n",
        "\n",
        "\n",
        "# Addestramento del Modello LightGBM (Baseline)\n",
        "if not df.empty:\n",
        "    lgbm_model_baseline = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbose=-1)\n",
        "    lgbm_model_baseline.fit(X_train_processed, y_train)\n",
        "\n",
        "    y_pred_baseline = lgbm_model_baseline.predict(X_test_processed)\n",
        "    y_pred_proba_baseline = lgbm_model_baseline.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "    print(\"Valutazione Modello Baseline:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
        "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_baseline):.4f}\")\n",
        "\n",
        "# Valutazione dell'Equità del Modello Baseline\n",
        "if not df.empty:\n",
        "    fairness_metrics_dict = {\n",
        "        'accuracy': accuracy_score,\n",
        "        'selection_rate': selection_rate,\n",
        "        'true_positive_rate': true_positive_rate,\n",
        "        'false_positive_rate': false_positive_rate,\n",
        "        'count': count\n",
        "    }\n",
        "\n",
        "    def print_fairness_metrics(y_true, y_pred, sensitive_features, attribute_name):\n",
        "        print(f\"\\n--- Equità rispetto a {attribute_name} ---\")\n",
        "        grouped_metrics = MetricFrame(metrics=fairness_metrics_dict,\n",
        "                                      y_true=y_true,\n",
        "                                      y_pred=y_pred,\n",
        "                                      sensitive_features=sensitive_features)\n",
        "        print(grouped_metrics.by_group)\n",
        "\n",
        "        dpd = demographic_parity_difference(y_true, y_pred, sensitive_features=sensitive_features)\n",
        "        print(f\"Demographic Parity Difference ({attribute_name}): {dpd:.4f}\")\n",
        "\n",
        "        eod = equalized_odds_difference(y_true, y_pred, sensitive_features=sensitive_features)\n",
        "        print(f\"Equalized Odds Difference ({attribute_name}): {eod:.4f}\")\n",
        "        return grouped_metrics, dpd, eod\n",
        "\n",
        "    print(\"\\n--- Valutazione Equità Modello Baseline ---\")\n",
        "    _, _, _ = print_fairness_metrics(y_test, y_pred_baseline, X_test_sensitive_gender, \"Gender (0=Male, 1=Female)\")\n",
        "    _, _, _ = print_fairness_metrics(y_test, y_pred_baseline, X_test_sensitive_race, \"Race (0=Non-White, 1=White)\")\n",
        "\n",
        "# Mitigazione del Bias con Pre-processing: FairSMOTE\n",
        "def apply_fairsmote(X_df, y_series, sensitive_feature_series, numerical_features, categorical_features, sensitive_attribute_name):\n",
        "    print(f\"\\nApplicazione di FairSMOTE per l'attributo: {sensitive_attribute_name}\")\n",
        "\n",
        "    df_train_temp = X_df.copy()\n",
        "    df_train_temp['target'] = y_series\n",
        "    df_train_temp['sensitive'] = sensitive_feature_series\n",
        "\n",
        "    subgroup_counts = df_train_temp.groupby(['target', 'sensitive']).size()\n",
        "    print(\"Dimensioni sottogruppi prima di FairSMOTE:\")\n",
        "    print(subgroup_counts)\n",
        "\n",
        "    if subgroup_counts.empty or len(subgroup_counts) < 2:\n",
        "        print(\"Numero insufficiente di sottogruppi, FairSMOTE non applicato.\")\n",
        "        return X_df.copy(), y_series.copy()\n",
        "\n",
        "    target_count = subgroup_counts.max()\n",
        "    print(f\"Dimensione target per sottogruppo: {target_count}\")\n",
        "\n",
        "    final_dfs = []\n",
        "\n",
        "    for name, group_df in df_train_temp.groupby(['target', 'sensitive']):\n",
        "        current_size = len(group_df)\n",
        "\n",
        "        if current_size >= target_count:\n",
        "            print(f\"Sottogruppo {name} (dim={current_size}) è un gruppo di maggioranza, non viene modificato.\")\n",
        "            final_dfs.append(group_df)\n",
        "            continue\n",
        "\n",
        "        samples_to_generate = target_count - current_size\n",
        "        print(f\"Sottogruppo {name} (dim={current_size}) è un gruppo di minoranza. Genero {samples_to_generate} campioni sintetici...\")\n",
        "\n",
        "        group_numerical_X = group_df[numerical_features]\n",
        "        group_categorical_X = group_df[categorical_features]\n",
        "\n",
        "        n_neighbors = min(current_size - 1, 5)\n",
        "\n",
        "        if n_neighbors < 1:\n",
        "            print(f\"   -> ATTENZIONE: Il sottogruppo {name} è troppo piccolo per SMOTE (n_samples <= 1). Eseguo Random Oversampling come fallback.\")\n",
        "            resampled_group = group_df.sample(n=samples_to_generate, replace=True, random_state=42)\n",
        "            final_dfs.append(pd.concat([group_df, resampled_group]))\n",
        "            continue\n",
        "\n",
        "        nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto')\n",
        "        nn.fit(group_numerical_X)\n",
        "\n",
        "        new_samples_list = []\n",
        "        random_indices = np.random.choice(group_numerical_X.index, size=samples_to_generate, replace=True)\n",
        "        neighbors_indices = nn.kneighbors(group_numerical_X, return_distance=False)\n",
        "\n",
        "        index_map = {index: i for i, index in enumerate(group_numerical_X.index)}\n",
        "\n",
        "        for i in random_indices:\n",
        "            base_sample_numerical = group_numerical_X.loc[i]\n",
        "\n",
        "            neighbor_pos = np.random.choice(neighbors_indices[index_map[i]][1:])\n",
        "            chosen_neighbor_index = group_numerical_X.index[neighbor_pos]\n",
        "            neighbor_sample_numerical = group_numerical_X.loc[chosen_neighbor_index]\n",
        "\n",
        "            diff = neighbor_sample_numerical - base_sample_numerical\n",
        "            synthetic_numerical = base_sample_numerical + np.random.random() * diff\n",
        "\n",
        "            synthetic_categorical = group_categorical_X.loc[i]\n",
        "\n",
        "            new_sample = pd.concat([\n",
        "                pd.Series(synthetic_numerical, index=numerical_features),\n",
        "                pd.Series(synthetic_categorical, index=categorical_features),\n",
        "                pd.Series({'target': name[0], 'sensitive': name[1]})\n",
        "            ])\n",
        "            new_samples_list.append(new_sample)\n",
        "\n",
        "        if new_samples_list:\n",
        "              new_samples_df = pd.DataFrame(new_samples_list)\n",
        "              final_dfs.append(pd.concat([group_df, new_samples_df]))\n",
        "        else:\n",
        "            final_dfs.append(group_df)\n",
        "\n",
        "    if not final_dfs:\n",
        "        print(\"Nessun dato generato, FairSMOTE non ha modificato i dati.\")\n",
        "        return X_df.copy(), y_series.copy()\n",
        "\n",
        "    df_fairsmote = pd.concat(final_dfs, ignore_index=True)\n",
        "\n",
        "    print(\"\\nDimensioni sottogruppi dopo FairSMOTE:\")\n",
        "    print(df_fairsmote.groupby(['target', 'sensitive']).size())\n",
        "\n",
        "    X_fairsmote = df_fairsmote.drop(columns=['target', 'sensitive'])\n",
        "    y_fairsmote = df_fairsmote['target']\n",
        "\n",
        "    return X_fairsmote, y_fairsmote\n",
        "\n",
        "\n",
        "if not 'df' in locals() or df.empty:\n",
        "    print(\"DataFrame 'df' non trovato o vuoto. Esecuzione saltata.\")\n",
        "    from sklearn.datasets import make_classification\n",
        "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, n_classes=2, random_state=42)\n",
        "    df = pd.DataFrame(X, columns=[f'num_{i}' for i in range(8)] + [f'cat_{i}' for i in range(2)])\n",
        "    df['target'] = y\n",
        "    df['gender'] = np.random.choice(['Male', 'Female'], size=1000, p=[0.7, 0.3])\n",
        "    df['race'] = np.random.choice(['A', 'B'], size=1000, p=[0.8, 0.2])\n",
        "    mask = (df['target'] == 1) & (df['gender'] == 'Female')\n",
        "    df = df.drop(df[mask].sample(frac=0.8, random_state=42).index)\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        df.drop('target', axis=1), df['target'], test_size=0.3, random_state=42\n",
        "    )\n",
        "    X_train_sensitive_gender_raw = X_train_raw['gender']\n",
        "    X_test_sensitive_gender = X_test_raw['gender']\n",
        "    X_test_sensitive_race = X_test_raw['race']\n",
        "\n",
        "    numerical_features = [col for col in X_train_raw.columns if 'num' in col]\n",
        "    categorical_features_to_encode = [col for col in X_train_raw.columns if 'cat' in col or col in ['gender', 'race']]\n",
        "\n",
        "    def preprocess_data(X_train, X_test, cat_feats, num_feats):\n",
        "        X_train_proc = pd.get_dummies(X_train, columns=[c for c in cat_feats if c in X_train.columns], drop_first=True)\n",
        "        X_test_proc = pd.get_dummies(X_test, columns=[c for c in cat_feats if c in X_test.columns], drop_first=True)\n",
        "        train_cols = X_train_proc.columns\n",
        "        test_cols = X_test_proc.columns\n",
        "        shared_cols = list(set(train_cols) & set(test_cols))\n",
        "        return X_train_proc[shared_cols], X_test_proc[shared_cols], None, None\n",
        "\n",
        "    def print_fairness_metrics(y_true, y_pred, sensitive_features, label):\n",
        "        print(f\"\\nMetriche di Fairness per {label}:\")\n",
        "        df_fairness = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'sensitive': sensitive_features})\n",
        "        print(df_fairness.groupby('sensitive')['y_pred'].mean())\n",
        "        return None, None, None\n",
        "\n",
        "X_train_fairsmote_gender, y_train_fairsmote_gender = apply_fairsmote(\n",
        "    X_df=X_train_raw,\n",
        "    y_series=y_train,\n",
        "    sensitive_feature_series=X_train_sensitive_gender_raw,\n",
        "    numerical_features=numerical_features,\n",
        "    categorical_features=categorical_features_to_encode,\n",
        "    sensitive_attribute_name=\"Gender\"\n",
        ")\n",
        "\n",
        "X_test_raw_copy_for_fairsmote_model = X_test_raw.copy()\n",
        "X_train_fairsmote_gender_processed_final, X_test_fairsmote_gender_processed_final, _, _ = preprocess_data(\n",
        "    X_train_fairsmote_gender, X_test_raw_copy_for_fairsmote_model,\n",
        "    categorical_features_to_encode, numerical_features\n",
        ")\n",
        "\n",
        "lgbm_fairsmote_gender = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, verbose=-1)\n",
        "lgbm_fairsmote_gender.fit(X_train_fairsmote_gender_processed_final, y_train_fairsmote_gender)\n",
        "\n",
        "y_pred_fairsmote_gender = lgbm_fairsmote_gender.predict(X_test_fairsmote_gender_processed_final)\n",
        "y_pred_proba_fairsmote_gender = lgbm_fairsmote_gender.predict_proba(X_test_fairsmote_gender_processed_final)[:,1]\n",
        "\n",
        "print(\"\\n--- Valutazione Modello DOPO FairSMOTE (Gender) ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_fairsmote_gender):.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_fairsmote_gender):.4f}\")\n",
        "print_fairness_metrics(y_test, y_pred_fairsmote_gender, X_test_sensitive_gender, \"Gender (Post-FairSMOTE)\")\n",
        "print_fairness_metrics(y_test, y_pred_fairsmote_gender, X_test_sensitive_race, \"Race (Post-FairSMOTE Gender)\")\n",
        "\n",
        "# Mitigazione del Bias con Post-processing: ThresholdOptimizer\n",
        "if not df.empty:\n",
        "    print(\"\\n--- Mitigazione Post-processing: ThresholdOptimizer ---\")\n",
        "    postprocess_gender = ThresholdOptimizer(\n",
        "        estimator=lgbm_model_baseline,\n",
        "        constraints=\"demographic_parity\",\n",
        "        objective=\"accuracy_score\",\n",
        "        prefit=True,\n",
        "        predict_method='predict_proba'\n",
        "    )\n",
        "    postprocess_gender.fit(X_train_processed, y_train, sensitive_features=X_train_sensitive_gender_raw)\n",
        "    y_pred_postprocess_gender = postprocess_gender.predict(X_test_processed, sensitive_features=X_test_sensitive_gender)\n",
        "\n",
        "    print(\"\\n--- Valutazione DOPO Mitigazione Post-processing per Gender (ThresholdOptimizer) ---\")\n",
        "    print(f\"Accuracy (PostProc-Gender): {accuracy_score(y_test, y_pred_postprocess_gender):.4f}\")\n",
        "    _, _, _ = print_fairness_metrics(y_test, y_pred_postprocess_gender, X_test_sensitive_gender, \"Gender (Post-ThresholdOptimizer, target: DemographicParity)\")\n",
        "\n",
        "    postprocess_race = ThresholdOptimizer(\n",
        "        estimator=lgbm_model_baseline,\n",
        "        constraints=\"demographic_parity\",\n",
        "        objective=\"accuracy_score\",\n",
        "        prefit=True,\n",
        "        predict_method='predict_proba'\n",
        "    )\n",
        "    postprocess_race.fit(X_train_processed, y_train, sensitive_features=X_train_sensitive_race_raw)\n",
        "    y_pred_postprocess_race = postprocess_race.predict(X_test_processed, sensitive_features=X_test_sensitive_race)\n",
        "\n",
        "    print(\"\\n--- Valutazione DOPO Mitigazione Post-processing per Race (ThresholdOptimizer) ---\")\n",
        "    print(f\"Accuracy (PostProc-Race): {accuracy_score(y_test, y_pred_postprocess_race):.4f}\")\n",
        "    _, _, _ = print_fairness_metrics(y_test, y_pred_postprocess_race, X_test_sensitive_race, \"Race (Post-ThresholdOptimizer, target: DemographicParity)\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xitiwYshcfr3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}